{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8efcb619",
   "metadata": {},
   "source": [
    "# Models Evaluation\n",
    "\n",
    "## Confusion Matrix\n",
    "It's a matrix thta summarizes all the possible outcomes of the classification. On the columns we have the actual (so, *real*) classes, whereas on the rows we have the *predicted* classes for the sample. <br>\n",
    "For example, let's consider a binary classification problem where we want to distinguish between two classes: *False* and *True**. The resulting confusion matrix might look like this:\n",
    "\n",
    "|  | Hf (Actual) | Ht (Actual) |\n",
    "|---|---|---|\n",
    "| **Hf (Predicted)** | 150 | 25 |\n",
    "| **Ht (Predicted)** | 10 | 215 |\n",
    "\n",
    "In this matrix:\n",
    "\n",
    "* **150** is the number of samples that were actually False and were correctly predicted as False (**TN** for the Hf class).\n",
    "* **25** is the number of samples that were actually True but were incorrectly predicted as False (**FN** for the Hf class).\n",
    "* **10** is the number of samples that were actually False but were incorrectly predicted as True (**FN** for the Hf class).\n",
    "* **215** is the number of samples that were actually True and were correctly predicted as True (**TP** for the Ht class).\n",
    "\n",
    "This confusion matrix provides a clear view of how many samples were classified correctly and what types of errors the model made. <br>\n",
    "\n",
    "Now, let's consider the **Iris** dataset, which has 3 classes. Let's import the *train/validation* split used before and fit the three Gaussian Generative Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a82ccb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTR shape: (4, 100)\n",
      "DVAL shape: (4, 50)\n",
      "LTR shape: (100,)\n",
      "LVAL shape: (50,)\n"
     ]
    }
   ],
   "source": [
    "#Import the train validation split from \"./split/iris_split.npz\"\n",
    "import numpy as np\n",
    "\n",
    "savedSplit = np.load('./split/iris_split.npz')\n",
    "\n",
    "DTR = savedSplit['DTR']\n",
    "DVAL = savedSplit['DVAL']\n",
    "LTR = savedSplit['LTR']\n",
    "LVAL = savedSplit['LVAL']\n",
    "\n",
    "print(f\"DTR shape: {DTR.shape}\")\n",
    "print(f\"DVAL shape: {DVAL.shape}\")\n",
    "print(f\"LTR shape: {LTR.shape}\")\n",
    "print(f\"LVAL shape: {LVAL.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f3a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "MVG_path = './models_finished/MVG'\n",
    "MVGTC_path = './models_finished/MVG_TiedCov'\n",
    "MVGNB_path = './models_finished/Naive_Bayes'\n",
    "if not MVG_path in sys.path:\n",
    "    sys.path.append(MVG_path)\n",
    "if not MVGTC_path in sys.path:\n",
    "    sys.path.append(MVGTC_path)\n",
    "if not MVGNB_path in sys.path:\n",
    "    sys.path.append(MVGNB_path)\n",
    "\n",
    "import MVG\n",
    "import MVG_TiedCov as MVGTC\n",
    "import Naive_Bayes as MVGNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddf285e",
   "metadata": {},
   "source": [
    "### Iris Dataset, MVG Classifier Confusion Matrix Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45e4dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MVG Pipeline\n",
    "\n",
    "def MVG_Pipeline(DTR, LTR, useLog=True):\n",
    "\n",
    "    ML_params_MVG = MVG.computeParams_ML(DTR, LTR)\n",
    "\n",
    "\n",
    "    S_LogLikelihoods_MVG = MVG.scoreMatrix_Pdf_GAU(DVAL, ML_params_MVG, useLog=useLog)\n",
    "    print(f\"S_LogLikelihoods_MVG shape, computed from the Validation Set: {S_LogLikelihoods_MVG.shape}\")\n",
    "\n",
    "    SJoint_MVG = MVG.computeSJoint(S_LogLikelihoods_MVG, np.ones((3, )) / 3., useLog=useLog) #compute the joint densities by multiplying the score matrix S with the Priors\n",
    "    print(f\"Joint densities shape: {SJoint_MVG.shape}\")\n",
    "\n",
    "    SPost_MVG = MVG.computePosteriors(SJoint_MVG, useLog=useLog) #compute the posteriors by normalizing the joint densities\n",
    "    print(f\"Posteriors shape: {SPost_MVG.shape}\")\n",
    "\n",
    "    PVAL_MVG = np.argmax(SPost_MVG, axis=0) #select the class with the highest posterior probability for each sample, set axis=0 to select the class with the highest posterior probability for each sample\n",
    "    print(f\"Predictions shape: {PVAL_MVG.shape}\")\n",
    "    print(f\"Predictions: {PVAL_MVG}\")\n",
    "\n",
    "    return PVAL_MVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61b73bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_LogLikelihoods_MVG shape, computed from the Validation Set: (3, 50)\n",
      "Joint densities shape: (3, 50)\n",
      "Posteriors shape: (3, 50)\n",
      "Predictions shape: (50,)\n",
      "Predictions: [0 0 1 2 2 0 0 0 1 1 0 0 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 2 1 0 1 2\n",
      " 2 0 1 1 2 1 0 0 0 2 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "PVAL_MVG = MVG_Pipeline(DTR, LTR, useLog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b685f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[19  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  2 14]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Compute confusion matrix\n",
    "#classes: 0, 1, 2\n",
    "\n",
    "Pred0_Actual0 = np.sum((PVAL_MVG == 0) & (LVAL == 0))    #True Positives for class 0\n",
    "Pred0_Actual1 = np.sum((PVAL_MVG == 0) & (LVAL == 1))    #False Positives for class 0 from class 1\n",
    "Pred0_Actual2 = np.sum((PVAL_MVG == 0) & (LVAL == 2))    #False Positives for class 0 from class 2\n",
    "\n",
    "Pred1_Actual0 = np.sum((PVAL_MVG == 1) & (LVAL == 0))    #False Positives for class 0 from class 1\n",
    "Pred1_Actual1 = np.sum((PVAL_MVG == 1) & (LVAL == 1))    #True Positives for class 1\n",
    "Pred1_Actual2 = np.sum((PVAL_MVG == 1) & (LVAL == 2))    #False Positives for class 1 from class 2\n",
    "\n",
    "Pred2_Actual0 = np.sum((PVAL_MVG == 2) & (LVAL == 0))    #False Positives for class 0 from class 2\n",
    "Pred2_Actual1 = np.sum((PVAL_MVG == 2) & (LVAL == 1))    #False Positives for class 1 from class 2\n",
    "Pred2_Actual2 = np.sum((PVAL_MVG == 2) & (LVAL == 2))    #True Positives for class 2\n",
    "\n",
    "#confMatrix is populated manually since I have compute all the values in the confusion matrix\n",
    "ConfMatrix_MVG_manual = np.array([[Pred0_Actual0, Pred0_Actual1, Pred0_Actual2],\n",
    "                       [Pred1_Actual0, Pred1_Actual1, Pred1_Actual2],\n",
    "                       [Pred2_Actual0, Pred2_Actual1, Pred2_Actual2]])\n",
    "\n",
    "print(f\"Confusion Matrix:\\n{ConfMatrix_MVG_manual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "97e81342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeConfMatrix(PVAL, LVAL):\n",
    "    \"\"\"\n",
    "    Compute the confusion matrix for the predicted labels and the actual labels.\n",
    "    Args:\n",
    "    - PVAL: Predicted labels\n",
    "    - LVAL: Actual labels\n",
    "    Returns:\n",
    "    - Confusion matrix\n",
    "    \"\"\"\n",
    "    numClasses = np.unique(LVAL).shape[0] #number of classes\n",
    "    ConfMatrix = np.zeros((numClasses, numClasses)) #initialize the confusion matrix with zeros\n",
    "\n",
    "    for classPredicted in range(numClasses):\n",
    "        #for each class find the tre positives and ALL the false negatives\n",
    "\n",
    "        classRow = np.array([]) #initialize the classRow with an empty array\n",
    "\n",
    "        for classActual in range(numClasses):\n",
    "            if classActual == classPredicted: \n",
    "                TP = np.sum((PVAL == classPredicted) & (LVAL == classPredicted))\n",
    "                classRow = np.append(classRow, TP)\n",
    "                continue\n",
    "\n",
    "            #compute each FP for each wrongly assigned label\n",
    "            FPi = np.sum((PVAL == classPredicted) & (LVAL == classActual))\n",
    "\n",
    "            #add FPi to the classCol\n",
    "            classRow = np.append(classRow, FPi)\n",
    "\n",
    "        \n",
    "        #add classCol to the confusion matrix\n",
    "        ConfMatrix[classPredicted, :] = classRow\n",
    "\n",
    "\n",
    "    return ConfMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fbeba67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix, MVG Classifier:\n",
      "[[19.  0.  0.]\n",
      " [ 0. 15.  0.]\n",
      " [ 0.  2. 14.]]\n"
     ]
    }
   ],
   "source": [
    "confMatrix_MVG = computeConfMatrix(PVAL_MVG, LVAL)\n",
    "print(f\"Confusion Matrix, MVG Classifier:\\n{confMatrix_MVG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c38c22",
   "metadata": {},
   "source": [
    "### Iris Dataset, Tied Covariance MVG Classifier Confusion Matrix Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "29f464d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MVGTC Pipeline\n",
    "\n",
    "def MVTC_Pipeline(DTR, LTR, useLog=True):\n",
    "    ML_params_MVGTC = MVGTC.computeParams_ML_TiedCov(DTR, LTR, useLDAForTiedCov=True)\n",
    "\n",
    "    S_LogLikelihoods_MVGTC = MVGTC.scoreMatrix_Pdf_GAU(DVAL, ML_params_MVGTC, useLog=useLog)\n",
    "    print(f\"S_LogLikelihoods_MVGTC shape, computed from the Validation Set: {S_LogLikelihoods_MVGTC.shape}\")\n",
    "\n",
    "    SJoint_MVGTC = MVGTC.computeSJoint(S_LogLikelihoods_MVGTC, np.ones((3, )) / 3., useLog=useLog) #compute the joint densities by multiplying the score matrix S with the Priors\n",
    "    print(f\"Joint densities shape: {SJoint_MVGTC.shape}\")\n",
    "\n",
    "    SPost_MVGTC = MVGTC.computePosteriors(SJoint_MVGTC, useLog=useLog) #compute the posteriors by normalizing the joint densities\n",
    "    print(f\"Posteriors shape: {SPost_MVGTC.shape}\")\n",
    "\n",
    "    PVAL_MVGTC = np.argmax(SPost_MVGTC, axis=0) #select the class with the highest posterior probability for each sample, set axis=0 to select the class with the highest posterior probability for each sample\n",
    "    print(f\"Predictions shape: {PVAL_MVGTC.shape}\")\n",
    "    print(f\"Predictions: {PVAL_MVGTC}\")\n",
    "\n",
    "    return PVAL_MVGTC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e0f859ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_LogLikelihoods_MVGTC shape, computed from the Validation Set: (3, 50)\n",
      "Joint densities shape: (3, 50)\n",
      "Posteriors shape: (3, 50)\n",
      "Predictions shape: (50,)\n",
      "Predictions: [0 0 1 2 2 0 0 0 1 1 0 0 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 1 1 0 1 2\n",
      " 2 0 1 1 2 1 0 0 0 2 1 2 0]\n",
      "\n",
      "Confusion Matrix, Tied Cov MVG Classifier:\n",
      "[[19.  0.  0.]\n",
      " [ 0. 16.  0.]\n",
      " [ 0.  1. 14.]]\n"
     ]
    }
   ],
   "source": [
    "confMatrix_MVGTC = computeConfMatrix(MVTC_Pipeline(DTR, LTR), LVAL)\n",
    "print(f\"\\nConfusion Matrix, Tied Cov MVG Classifier:\\n{confMatrix_MVGTC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a6582",
   "metadata": {},
   "source": [
    "### Iris Dataset, Naive Bayes MVG Classifier Confusion Matrix Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dfdd9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Pipeline\n",
    "\n",
    "def MVGNB_Pipeline(DTR, LTR, useLog=True):\n",
    "\n",
    "    ML_params_MVGNB = MVGNB.computeParams_ML_NaiveBayesAssumption(DTR, LTR)\n",
    "\n",
    "    S_LogLikelihoods_MVGNB = MVGNB.scoreMatrix_Pdf_GAU(DVAL, ML_params_MVGNB, useLog=True)\n",
    "    print(f\"S_LogLikelihoods_MVGNB shape, computed from the Validation Set: {S_LogLikelihoods_MVGNB.shape}\")\n",
    "\n",
    "    SJoint_MVGNB = MVGNB.computeSJoint(S_LogLikelihoods_MVGNB, np.ones((3, )) / 3., useLog=True) #compute the joint densities by multiplying the score matrix S with the Priors\n",
    "    print(f\"Joint densities shape: {SJoint_MVGNB.shape}\")\n",
    "\n",
    "    SPost_MVGNB = MVGNB.computePosteriors(SJoint_MVGNB, useLog=True) #compute the posteriors by normalizing the joint densities\n",
    "    print(f\"Posteriors shape: {SPost_MVGNB.shape}\")\n",
    "\n",
    "    PVAL_MVGNB = np.argmax(SPost_MVGNB, axis=0) #select the class with the highest posterior probability for each sample, set axis=0 to select the class with the highest posterior probability for each sample\n",
    "    print(f\"Predictions shape: {PVAL_MVGNB.shape}\")\n",
    "    print(f\"Predictions: {PVAL_MVGNB}\")\n",
    "\n",
    "    return PVAL_MVGNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1b88baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_LogLikelihoods_MVGNB shape, computed from the Validation Set: (3, 50)\n",
      "Joint densities shape: (3, 50)\n",
      "Posteriors shape: (3, 50)\n",
      "Predictions shape: (50,)\n",
      "Predictions: [0 0 1 2 2 0 0 0 1 1 0 0 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 1 2 0 1 2\n",
      " 2 0 1 1 2 1 0 0 0 2 1 2 0]\n",
      "\n",
      "Confusion Matrix, Naive Bayes MVG Classifier:\n",
      "[[19.  0.  0.]\n",
      " [ 0. 15.  0.]\n",
      " [ 0.  2. 14.]]\n"
     ]
    }
   ],
   "source": [
    "confMatrix_MVGNB = computeConfMatrix(MVGNB_Pipeline(DTR, LTR), LVAL)\n",
    "print(f\"\\nConfusion Matrix, Naive Bayes MVG Classifier:\\n{confMatrix_MVGNB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319bad2",
   "metadata": {},
   "source": [
    "Given the limited number of errors, a detailed analysis of the IRIS dataset is not very interesting. We\n",
    "thus turn our attention to a larger evaluation dataset. <br>\n",
    "We can use the dataset used in Lab7, storing the tercets samples of the *Divina Commedia*. Each tercet is associated to a label that denotes the cantica from where tercet is extracted ($0$: *Inferno*, $1$ = *Purgatorio*, $2$ = *Paradiso*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b3dd6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "commedia_ll = np.load(\"./data/commedia_ll.npy\")\n",
    "commedia_labels = np.load(\"./data/commedia_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3747bdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commedia_ll shape: (3, 1204)\n",
      "commedia_labels shape: (1204,)\n",
      "First 10 logLikelihoods of Inferno: [-122.72443339 -133.30648701 -134.36987251 -170.65723182 -163.97348133\n",
      " -139.39515141 -166.71004347 -174.57737603 -147.62396153 -123.47570192]\n",
      "First 10 labels: [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"commedia_ll shape: {commedia_ll.shape}\")\n",
    "print(f\"commedia_labels shape: {commedia_labels.shape}\")\n",
    "print(f\"First 10 logLikelihoods of Inferno: {commedia_ll[0, :10]}\")\n",
    "print(f\"First 10 labels: {commedia_labels[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694e6579",
   "metadata": {},
   "source": [
    "Let's create a new function that computes the confusionMatrix given the log-likelihoods and the Priors. The classification rule used is always the maximum Posterior class probability Decisions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d28ee959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#always import MVG before using this function!\n",
    "\n",
    "def computeConfMatrixFromLL(LVAL, logLikelihoods, Priors, useLog=True):\n",
    "    \"\"\"\n",
    "    Compute the confusion matrix for the predicted labels and the actual labels.\n",
    "    Args:\n",
    "    - logLikelihoods: matriix of log likelihoods for each class\n",
    "    - Priors: array of priors for each class, priors are application dependent\n",
    "    - useLog: if True, use log likelihoods, else use normal likelihoods\n",
    "\n",
    "    Returns:\n",
    "    - Confusion matrix\n",
    "    \"\"\"\n",
    "\n",
    "    SJoint = MVG.computeSJoint(logLikelihoods, Priors, useLog=useLog) #compute the joint densities by multiplying the score matrix S with the Priors\n",
    "    SPost = MVG.computePosteriors(SJoint, useLog=True)  #compute the posteriors by normalizing the joint densities\n",
    "    PVAL = np.argmax(SPost, axis=0) #select the class with the highest posterior probability for each sample, set axis=0 to select the class with the highest posterior probability for each sample\n",
    "\n",
    "    #call the computeConfMatrix function to compute the confusion matrix\n",
    "    return computeConfMatrix(PVAL, LVAL)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072842f8",
   "metadata": {},
   "source": [
    "For computing the Confusion Matrix for the *Commedia* dataset, we assume uniform Priors for each cantica: $P(l\\_lInf) = P(l\\_lPur) = P(l\\_lPar) = \\frac{1}{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b05108ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix, Commedia Classifier:\n",
      "[[210. 113.  61.]\n",
      " [137. 191. 111.]\n",
      " [ 53.  98. 230.]]\n"
     ]
    }
   ],
   "source": [
    "#Compute the confusion matrix for the log likelihoods\n",
    "#Assume uniform priors for each class\n",
    "\n",
    "confMatrix_Commedia = computeConfMatrixFromLL(commedia_labels, commedia_ll, np.ones((3, )) / 3., useLog=True)\n",
    "print(f\"\\nConfusion Matrix, Commedia Classifier:\\n{confMatrix_Commedia}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0a1371",
   "metadata": {},
   "source": [
    "## Optimal Bayes decision\n",
    "The goal of a classifier is to allow us to choose an action $a$ to perform among\n",
    "a set of actions $\\mathcal{A}$. In the context of classification, an action can be simply \"Classify sample $x_t$ with label $k$\", although we can have also more complex types of actions. <br> \n",
    "We can associate to each action a **cost** $C(a \\mid k)$ that we have to pay when we choose action $a$ and the sample belongs to class $k$. This can be seen as a missclassification cost, which depends both on the actual and predicted class. <br>\n",
    "Unluckily, at evaluation time we don't know the actual classes of the samples (what whould the point of classification be, otherwise?), but we have access to the Priors and we can calculate the Posterios. These are useful to compute the costs. <br>\n",
    "For a $K$-class (where classes are numbered from $0$ up to $K-1$) problem, let's denote the Priors as:\n",
    "$$\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
