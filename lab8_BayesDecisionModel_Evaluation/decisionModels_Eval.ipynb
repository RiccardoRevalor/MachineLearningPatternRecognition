{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8efcb619",
   "metadata": {},
   "source": [
    "# Models Evaluation\n",
    "\n",
    "## Confusion Matrix\n",
    "It's a matrix thta summarizes all the possible outcomes of the classification. On the columns we have the actual (so, *real*) classes, whereas on the rows we have the *predicted* classes for the sample. <br>\n",
    "For example, let's consider a binary classification problem where we want to distinguish between two classes: *False* and *True**. The resulting confusion matrix might look like this:\n",
    "\n",
    "|  | Hf (Actual) | Ht (Actual) |\n",
    "|---|---|---|\n",
    "| **Hf (Predicted)** | 150 | 25 |\n",
    "| **Ht (Predicted)** | 10 | 215 |\n",
    "\n",
    "In this matrix:\n",
    "\n",
    "* **150** is the number of samples that were actually False and were correctly predicted as False (**TN** for the Hf class).\n",
    "* **25** is the number of samples that were actually True but were incorrectly predicted as False (**FN** for the Hf class).\n",
    "* **10** is the number of samples that were actually False but were incorrectly predicted as True (**FN** for the Hf class).\n",
    "* **215** is the number of samples that were actually True and were correctly predicted as True (**TP** for the Ht class).\n",
    "\n",
    "This confusion matrix provides a clear view of how many samples were classified correctly and what types of errors the model made. <br>\n",
    "\n",
    "Now, let's consider the **Iris** dataset, which has 3 classes. Let's import the *train/validation* split used before and fit the three Gaussian Generative Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a82ccb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTR shape: (4, 100)\n",
      "DVAL shape: (4, 50)\n",
      "LTR shape: (100,)\n",
      "LVAL shape: (50,)\n"
     ]
    }
   ],
   "source": [
    "#Import the train validation split from \"./split/iris_split.npz\"\n",
    "import numpy as np\n",
    "\n",
    "savedSplit = np.load('./split/iris_split.npz')\n",
    "\n",
    "DTR = savedSplit['DTR']\n",
    "DVAL = savedSplit['DVAL']\n",
    "LTR = savedSplit['LTR']\n",
    "LVAL = savedSplit['LVAL']\n",
    "\n",
    "print(f\"DTR shape: {DTR.shape}\")\n",
    "print(f\"DVAL shape: {DVAL.shape}\")\n",
    "print(f\"LTR shape: {LTR.shape}\")\n",
    "print(f\"LVAL shape: {LVAL.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f3a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "MVG_path = './models_finished/MVG'\n",
    "MVGTC_path = './models_finished/MVG_TiedCov'\n",
    "MVGNB_path = './models_finished/Naive_Bayes'\n",
    "if not MVG_path in sys.path:\n",
    "    sys.path.append(MVG_path)\n",
    "if not MVGTC_path in sys.path:\n",
    "    sys.path.append(MVGTC_path)\n",
    "if not MVGNB_path in sys.path:\n",
    "    sys.path.append(MVGNB_path)\n",
    "\n",
    "import MVG\n",
    "import MVG_TiedCov as MVGTC\n",
    "import Naive_Bayes as MVGNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddf285e",
   "metadata": {},
   "source": [
    "### Iris Dataset, MVG Classifier Confusion Matrix Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45e4dbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_LogLikelihoods_MVG shape, computed from the Validation Set: (3, 50)\n",
      "Joint densities shape: (3, 50)\n",
      "Posteriors shape: (3, 50)\n",
      "Predictions shape: (50,)\n",
      "Predictions: [0 0 1 2 2 0 0 0 1 1 0 0 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 2 1 0 1 2\n",
      " 2 0 1 1 2 1 0 0 0 2 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "#MVG Pipeline\n",
    "\n",
    "ML_params_MVG = MVG.computeParams_ML(DTR, LTR)\n",
    "\n",
    "\n",
    "S_LogLikelihoods_MVG = MVG.scoreMatrix_Pdf_GAU(DVAL, ML_params_MVG, useLog=True)\n",
    "print(f\"S_LogLikelihoods_MVG shape, computed from the Validation Set: {S_LogLikelihoods_MVG.shape}\")\n",
    "\n",
    "SJoint_MVG = MVG.computeSJoint(S_LogLikelihoods_MVG, np.ones((3, )) / 3., useLog=True) #compute the joint densities by multiplying the score matrix S with the Priors\n",
    "print(f\"Joint densities shape: {SJoint_MVG.shape}\")\n",
    "\n",
    "SPost_MVG = MVG.computePosteriors(SJoint_MVG, useLog=True) #compute the posteriors by normalizing the joint densities\n",
    "print(f\"Posteriors shape: {SPost_MVG.shape}\")\n",
    "\n",
    "PVAL_MVG = np.argmax(SPost_MVG, axis=0) #select the class with the highest posterior probability for each sample, set axis=0 to select the class with the highest posterior probability for each sample\n",
    "print(f\"Predictions shape: {PVAL_MVG.shape}\")\n",
    "print(f\"Predictions: {PVAL_MVG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b685f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[19  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  2 14]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Compute confusion matrix\n",
    "#classes: 0, 1, 2\n",
    "\n",
    "Pred0_Actual0 = np.sum((PVAL_MVG == 0) & (LVAL == 0))    #True Positives for class 0\n",
    "Pred0_Actual1 = np.sum((PVAL_MVG == 0) & (LVAL == 1))    #False Positives for class 0 from class 1\n",
    "Pred0_Actual2 = np.sum((PVAL_MVG == 0) & (LVAL == 2))    #False Positives for class 0 from class 2\n",
    "\n",
    "Pred1_Actual0 = np.sum((PVAL_MVG == 1) & (LVAL == 0))    #False Positives for class 0 from class 1\n",
    "Pred1_Actual1 = np.sum((PVAL_MVG == 1) & (LVAL == 1))    #True Positives for class 1\n",
    "Pred1_Actual2 = np.sum((PVAL_MVG == 1) & (LVAL == 2))    #False Positives for class 1 from class 2\n",
    "\n",
    "Pred2_Actual0 = np.sum((PVAL_MVG == 2) & (LVAL == 0))    #False Positives for class 0 from class 2\n",
    "Pred2_Actual1 = np.sum((PVAL_MVG == 2) & (LVAL == 1))    #False Positives for class 1 from class 2\n",
    "Pred2_Actual2 = np.sum((PVAL_MVG == 2) & (LVAL == 2))    #True Positives for class 2\n",
    "\n",
    "#confMatrix is populated manually since I have compute all the values in the confusion matrix\n",
    "ConfMatrix_MVG_manual = np.array([[Pred0_Actual0, Pred0_Actual1, Pred0_Actual2],\n",
    "                       [Pred1_Actual0, Pred1_Actual1, Pred1_Actual2],\n",
    "                       [Pred2_Actual0, Pred2_Actual1, Pred2_Actual2]])\n",
    "\n",
    "print(f\"Confusion Matrix:\\n{ConfMatrix_MVG_manual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97e81342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeConfMatrix(PVAL, LVAL):\n",
    "    \"\"\"\n",
    "    Compute the confusion matrix for the predicted labels and the actual labels.\n",
    "    Args:\n",
    "        PVAL: Predicted labels\n",
    "        LVAL: Actual labels\n",
    "    Returns:\n",
    "        Confusion matrix\n",
    "    \"\"\"\n",
    "    numClasses = np.unique(LVAL).shape[0] #number of classes\n",
    "    ConfMatrix = np.zeros((numClasses, numClasses)) #initialize the confusion matrix with zeros\n",
    "\n",
    "    for classPredicted in range(numClasses):\n",
    "        #for each class find the tre positives and ALL the false negatives\n",
    "\n",
    "        classRow = np.array([]) #initialize the classRow with an empty array\n",
    "\n",
    "        for classActual in range(numClasses):\n",
    "            if classActual == classPredicted: \n",
    "                TP = np.sum((PVAL == classPredicted) & (LVAL == classPredicted))\n",
    "                classRow = np.append(classRow, TP)\n",
    "                continue\n",
    "\n",
    "            #compute each FP for each wrongly assigned label\n",
    "            FPi = np.sum((PVAL == classPredicted) & (LVAL == classActual))\n",
    "\n",
    "            #add FPi to the classCol\n",
    "            classRow = np.append(classRow, FPi)\n",
    "\n",
    "        \n",
    "        #add classCol to the confusion matrix\n",
    "        ConfMatrix[classPredicted, :] = classRow\n",
    "\n",
    "\n",
    "    return ConfMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fbeba67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix, MVG Classifier:\n",
      "[[19.  0.  0.]\n",
      " [ 0. 15.  0.]\n",
      " [ 0.  2. 14.]]\n"
     ]
    }
   ],
   "source": [
    "confMatrix_MVG = computeConfMatrix(PVAL_MVG, LVAL)\n",
    "print(f\"Confusion Matrix, MVG Classifier:\\n{confMatrix_MVG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c38c22",
   "metadata": {},
   "source": [
    "### Iris Dataset, Tied Covariance MVG Classifier Confusion Matrix Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "29f464d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_LogLikelihoods_MVGTC shape, computed from the Validation Set: (3, 50)\n",
      "Joint densities shape: (3, 50)\n",
      "Posteriors shape: (3, 50)\n",
      "Predictions shape: (50,)\n",
      "Predictions: [0 0 1 2 2 0 0 0 1 1 0 0 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 1 1 0 1 2\n",
      " 2 0 1 1 2 1 0 0 0 2 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "#MVGTC Pipeline\n",
    "\n",
    "ML_params_MVGTC = MVGTC.computeParams_ML_TiedCov(DTR, LTR, useLDAForTiedCov=True)\n",
    "\n",
    "S_LogLikelihoods_MVGTC = MVGTC.scoreMatrix_Pdf_GAU(DVAL, ML_params_MVGTC, useLog=True)\n",
    "print(f\"S_LogLikelihoods_MVGTC shape, computed from the Validation Set: {S_LogLikelihoods_MVGTC.shape}\")\n",
    "\n",
    "SJoint_MVGTC = MVGTC.computeSJoint(S_LogLikelihoods_MVGTC, np.ones((3, )) / 3., useLog=True) #compute the joint densities by multiplying the score matrix S with the Priors\n",
    "print(f\"Joint densities shape: {SJoint_MVGTC.shape}\")\n",
    "\n",
    "SPost_MVGTC = MVGTC.computePosteriors(SJoint_MVGTC, useLog=True) #compute the posteriors by normalizing the joint densities\n",
    "print(f\"Posteriors shape: {SPost_MVGTC.shape}\")\n",
    "\n",
    "PVAL_MVGTC = np.argmax(SPost_MVGTC, axis=0) #select the class with the highest posterior probability for each sample, set axis=0 to select the class with the highest posterior probability for each sample\n",
    "print(f\"Predictions shape: {PVAL_MVGTC.shape}\")\n",
    "print(f\"Predictions: {PVAL_MVGTC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e0f859ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix, Tied Cov MVG Classifier:\n",
      "[[19.  0.  0.]\n",
      " [ 0. 16.  0.]\n",
      " [ 0.  1. 14.]]\n"
     ]
    }
   ],
   "source": [
    "confMatrix_MVGTC = computeConfMatrix(PVAL_MVGTC, LVAL)\n",
    "print(f\"Confusion Matrix, Tied Cov MVG Classifier:\\n{confMatrix_MVGTC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a6582",
   "metadata": {},
   "source": [
    "### Iris Dataset, Naive Bayes MVG Classifier Confusion Matrix Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dfdd9af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_LogLikelihoods_MVGNB shape, computed from the Validation Set: (3, 50)\n",
      "Joint densities shape: (3, 50)\n",
      "Posteriors shape: (3, 50)\n",
      "Predictions shape: (50,)\n",
      "Predictions: [0 0 1 2 2 0 0 0 1 1 0 0 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 1 2 0 1 2\n",
      " 2 0 1 1 2 1 0 0 0 2 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Pipeline\n",
    "\n",
    "ML_params_MVGNB = MVGNB.computeParams_ML_NaiveBayesAssumption(DTR, LTR)\n",
    "\n",
    "S_LogLikelihoods_MVGNB = MVGNB.scoreMatrix_Pdf_GAU(DVAL, ML_params_MVGNB, useLog=True)\n",
    "print(f\"S_LogLikelihoods_MVGNB shape, computed from the Validation Set: {S_LogLikelihoods_MVGNB.shape}\")\n",
    "\n",
    "SJoint_MVGNB = MVGNB.computeSJoint(S_LogLikelihoods_MVGNB, np.ones((3, )) / 3., useLog=True) #compute the joint densities by multiplying the score matrix S with the Priors\n",
    "print(f\"Joint densities shape: {SJoint_MVGNB.shape}\")\n",
    "\n",
    "SPost_MVGNB = MVGNB.computePosteriors(SJoint_MVGNB, useLog=True) #compute the posteriors by normalizing the joint densities\n",
    "print(f\"Posteriors shape: {SPost_MVGNB.shape}\")\n",
    "\n",
    "PVAL_MVGNB = np.argmax(SPost_MVGNB, axis=0) #select the class with the highest posterior probability for each sample, set axis=0 to select the class with the highest posterior probability for each sample\n",
    "print(f\"Predictions shape: {PVAL_MVGNB.shape}\")\n",
    "print(f\"Predictions: {PVAL_MVGNB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1b88baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix, Naive Bayes MVG Classifier:\n",
      "[[19.  0.  0.]\n",
      " [ 0. 15.  0.]\n",
      " [ 0.  2. 14.]]\n"
     ]
    }
   ],
   "source": [
    "confMatrix_MVGNB = computeConfMatrix(PVAL_MVGNB, LVAL)\n",
    "print(f\"Confusion Matrix, Naive Bayes MVG Classifier:\\n{confMatrix_MVGNB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319bad2",
   "metadata": {},
   "source": [
    "Given the limited number of errors, a detailed analysis of the IRIS dataset is not very interesting. We\n",
    "thus turn our attention to a larger evaluation dataset. <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
